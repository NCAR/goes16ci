log_level: 20
data_path: "/glade/scratch/gwallach/goes16_nc/ABI_patches/" # Path to data
split_date: "2019-06-16" # Date for splitting training and testing examples
conv_net_parameters:
  min_filters: 32 # number of convolutional filters in first layer
  use_dropout: 0 # if 1 use dropout, 0 don't use dropout
  dropout_alpha: 0.1 # if use_dropout is 1, then dropout rate
  verbose: 1 # level of verbosity
  epochs: 2 # number of epochs for training
  learning_rate: 0.0001 # learning rate
  batch_size: 1024 # number of batches
  loss: "binary_crossentropy" # type of loss
  metrics: ["mean_squared_error"] # additional metrics
cpu: 1 # if 1 run cpu training, if 0 skip
num_cpus: 35 # number of CPUS to use for training, set to number of CPUs in node
single_gpu: 1 # if 1, run single GPU training, if 0 skip
multi_gpu: 1 # if 1, run multi-GPU training, if 0 skip
num_gpus: 8 # max number of GPUs to evaluate in multi-GPU training, will test up to 8 between 1, 2, 4, and 8
scale_batch_size: 1 # if 1 multiply the batch size by the number of GPUs, if 0 keep batch size the same
dtype: "float32" # data type for neural network
random_seed: 4832 # random seed integer
out_path: "./benchmark_output_default" # directory to output yml and csv files
